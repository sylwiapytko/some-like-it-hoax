{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploratory data analysis for the dataset of the paper\n",
    "\n",
    "Author: Marco Della Vedova - marco.dellavedova@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "from eda_utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading two json files of the fb02 dataset: \n",
    "# 1) the postid:[userids] dictionary representing likes and \n",
    "# 2) the pageid:hoaxflag dictionary\n",
    "with open('../dataset/retweeters.json') as data_file:\n",
    "    datadict = json.load(data_file)\n",
    "with open('accountClassification.json') as pagedatafile:\n",
    "    hoaxpagedict = json.load(pagedatafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages: 10 hoax vs. 10 non-hoax\n",
      "Pages used: 19\n"
     ]
    }
   ],
   "source": [
    "# Get hoax pages and non-hoax pages lists from the hoaxpages dict for convenience \n",
    "pages_hoax = [pageid for pageid in hoaxpagedict.keys() if hoaxpagedict[pageid]]\n",
    "pages_nonhoax = [pageid for pageid in hoaxpagedict.keys() if not hoaxpagedict[pageid]]\n",
    "print(\"Pages: %d hoax vs. %d non-hoax\" % (len(pages_hoax), len(pages_nonhoax)))\n",
    "print(\"Pages used: %d\" % len(set([i.split('_')[0] for i in datadict.keys()])))\n",
    "\n",
    "# Check integrity\n",
    "# len(set([i.split('_')[0] for i in datadict.keys()])) == (len(pages_nonhoax) + len(pages_hoax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic statistics about dataset \n",
    "def print_stat(data):\n",
    "    nposts = len(data)\n",
    "    nposts_h = len(list(filter(is_hoax, data)))\n",
    "    \n",
    "    nusers = get_number_of_users(data)\n",
    "    likes_hoax, likes_nhoax = split_likes(data)\n",
    "    hoax_likers = set(likes_hoax)\n",
    "    nonhoax_likers = set(likes_nhoax)\n",
    "    both_likers = nonhoax_likers.intersection(hoax_likers)\n",
    "    nusers_intesection = len(both_likers)\n",
    "    nusers_hoaxonly = len(hoax_likers) - nusers_intesection\n",
    "    nusers_nonhoaxonly = len(nonhoax_likers) - nusers_intesection\n",
    "    \n",
    "    nlikes = get_number_of_likes(data)\n",
    "    \n",
    "    data_post = [len(likes) for _, likes in data.items()]\n",
    "    \n",
    "    from collections import Counter\n",
    "    data_user = list(Counter(likes_hoax+likes_nhoax).values())\n",
    "    \n",
    "    print(\"N. of posts: %d = %d hoax + %d nonhoax\" %\n",
    "          (nposts, nposts_h, nposts-nposts_h))\n",
    "    print(\"N. of users: %d = %d hoax-only + %d nonhoax-only + %d intersect\" % \n",
    "          (nusers, nusers_hoaxonly, nusers_nonhoaxonly, nusers_intesection))\n",
    "    print(\"N. of likes: %d = %d hoax + %d nonhoax\" % \n",
    "          (nlikes, len(likes_hoax), len(likes_nhoax)))\n",
    "    print(\"Likes per post: avg. %.1f, median %d, max %d\" %\n",
    "          (np.average(data_post), np.median(data_post), np.max(data_post)))\n",
    "    print(\"Likes per user: avg. %.1f, median %d, max %d\" %\n",
    "          (np.average(data_user), np.median(data_user), np.max(data_user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. of posts: 9270 = 3438 hoax + 5832 nonhoax\n",
      "N. of users: 4530 = 1731 hoax-only + 2213 nonhoax-only + 586 intersect\n",
      "N. of likes: 22916 = 14855 hoax + 8061 nonhoax\n",
      "Likes per post: avg. 2.5, median 0, max 50\n",
      "Likes per user: avg. 5.1, median 1, max 833\n"
     ]
    }
   ],
   "source": [
    "# Statistics for all the dataset\n",
    "print_stat(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. of posts: 590 = 429 hoax + 161 nonhoax\n",
      "N. of users: 3314 = 1512 hoax-only + 1448 nonhoax-only + 354 intersect\n",
      "N. of likes: 12666 = 9420 hoax + 3246 nonhoax\n",
      "Likes per post: avg. 21.5, median 17, max 50\n",
      "Likes per user: avg. 3.8, median 1, max 245\n"
     ]
    }
   ],
   "source": [
    "datafp = filter_post(datadict, 10)\n",
    "print_stat(datafp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. of posts: 9270 = 3438 hoax + 5832 nonhoax\n",
      "N. of users: 4530 = 1731 hoax-only + 2213 nonhoax-only + 586 intersect\n",
      "N. of likes: 22916 = 14855 hoax + 8061 nonhoax\n",
      "Likes per post: avg. 2.5, median 0, max 50\n",
      "Likes per user: avg. 5.1, median 1, max 833\n"
     ]
    }
   ],
   "source": [
    "datafu = filter_user(datadict, 1)\n",
    "print_stat(datafu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count user likes split into hoax-likes and nonhoax-likes\n",
    "def likes_per_user_split_count(data, f=lambda x: True):\n",
    "    from collections import Counter\n",
    "    # f = lambda x: x in both_likers\n",
    "    # u = both_likers\n",
    "    # f = lambda x: True\n",
    "    u = list(filter(f, get_user_set(data)))\n",
    "    likes_hoax, likes_nhoax = split_likes(data)\n",
    "    likes_hoax_counter = Counter(filter(f, likes_hoax))\n",
    "    likes_nhoax_counter = Counter(filter(f, likes_nhoax))\n",
    "    userlikes_split = np.zeros([len(u), 2])\n",
    "    for i, userid in enumerate(u):\n",
    "        userlikes_split[i, 0] = likes_hoax_counter[userid]\n",
    "        userlikes_split[i, 1] = likes_nhoax_counter[userid]\n",
    "    return userlikes_split\n",
    "# userlikes_split = splitlikes(datafu)\n",
    "# userlikes_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_hoax, likes_nhoax = split_likes(datadict)\n",
    "hoax_likers = set(likes_hoax)\n",
    "nonhoax_likers = set(likes_nhoax)\n",
    "both_likers = nonhoax_likers.intersection(hoax_likers)\n",
    "len(both_likers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib configuration for better view in latex\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('figure', figsize='4, 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the likes per post distribution\n",
    "maxlikes = 200\n",
    "bins = list(range(0,maxlikes+1,10))\n",
    "\n",
    "hoax_nlikes_f = [len(likes) for post_id, likes in datadict.items() if is_hoax(post_id)]\n",
    "nhoax_nlikes_f = [len(likes) for post_id, likes in datadict.items() if not is_hoax(post_id)]\n",
    "\n",
    "#n, _, p1 = plt.hist(list(filter(lambda x: x<=maxlikes, nhoax_nlikes_f)),bins=bins, alpha=0)\n",
    "n, bin_edges = np.histogram(list(filter(lambda x: x<=maxlikes, hoax_nlikes_f)),bins=bins)\n",
    "p2 = plt.plot(range(5,maxlikes+1,10),n, marker='D', linestyle='', color='red')\n",
    "_, _, p3 = plt.hist(list(filter(lambda x: x<=maxlikes, nhoax_nlikes_f)), bins=bins, alpha=0.5, color='green')\n",
    "\n",
    "plt.xlim([0,maxlikes])\n",
    "plt.yscale('log')\n",
    "plt.title(\"Likes per post\")\n",
    "plt.xlabel(\"N. of likes\")\n",
    "plt.ylabel(\"N. of posts\")\n",
    "plt.legend(labels=[\"Hoax posts\", \"Non hoax posts\"])\n",
    "plt.savefig(\"postlikes_hist.pdf\")\n",
    "plt.show()\n",
    "print(\"Likes per post (avg.): %.1f hoax vs %.1f non-hoax\" % (np.average(hoax_nlikes_f), np.average(nhoax_nlikes_f)))\n",
    "print(\"Likes per post (median): %.1f hoax vs %.1f non-hoax\" % (np.median(hoax_nlikes_f), np.median(nhoax_nlikes_f)))\n",
    "print(\"Likes per post (max): %d hoax vs %d non-hoax\" % (np.max(hoax_nlikes_f), np.max(nhoax_nlikes_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of likes per user distribution\n",
    "maxlikes = 200\n",
    "minlikes = 0\n",
    "bins = list(range(minlikes,maxlikes+1,10))\n",
    "from collections import Counter\n",
    "user_nlikes = [x for x in Counter(likes_hoax+likes_nhoax).values()]\n",
    "bothuser_nlikes = [x for x in Counter(filter(lambda x: x in both_likers,\n",
    "                                             likes_hoax+likes_nhoax)\n",
    "                                      ).values()]\n",
    "n, bin_edges = np.histogram(bothuser_nlikes, \n",
    "                            bins=bins)\n",
    "# p2 = plt.plot(range(5,maxlikes+1,10),n, marker='D', linestyle='', color='yellow')\n",
    "\n",
    "plt.hist(list(filter(lambda x: x<=maxlikes and x>=minlikes, user_nlikes)), bins=bins, alpha=0.75, color='blue')\n",
    "plt.xlim([minlikes, maxlikes])\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"N. of likes\")\n",
    "plt.ylabel(\"N. of users\")\n",
    "plt.title(\"Likes per user\")\n",
    "# plt.legend(labels=[\"Intersection dataset\", \"Complete dataset\"])\n",
    "plt.savefig(\"userlikes_hist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "data_user = Counter(Counter(likes_hoax+likes_nhoax).values())\n",
    "print(\"N. of users with one single like: %d (%.1f%%)\" % (data_user[1], 100*data_user[1]/get_number_of_users(datadict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: hoax likes vs. nonhoax likes\n",
    "userlikes_split = likes_per_user_split_count(datafu)\n",
    "minlike = 10\n",
    "xylim = 50\n",
    "mask = (userlikes_split[:,0] + userlikes_split[:,1] >= minlike) \\\n",
    "    * (userlikes_split[:,0] <= xylim) \\\n",
    "    * (userlikes_split[:,1] <= xylim)\n",
    "\n",
    "x = userlikes_split[mask, 0]\n",
    "y = userlikes_split[mask, 1]\n",
    "plt.scatter(x, y, alpha=0.2)\n",
    "plt.xlim([0,xylim])\n",
    "plt.ylim([0,xylim])\n",
    "plt.xlabel(\"Likes to hoax posts\")\n",
    "plt.ylabel(\"Likes to non-hoax posts\")\n",
    "plt.savefig(\"bothusers_scatter.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap plot: hoax likes vs. nonhoax likes\n",
    "userlikes_split = likes_per_user_split_count(datafu)\n",
    "xylim = 40\n",
    "from matplotlib.colors import LogNorm\n",
    "x = userlikes_split[:,0]\n",
    "y = userlikes_split[:,1]\n",
    "mask = (x <= xylim) * (y <= xylim)\n",
    "plt.hist2d(x[mask], y[mask], bins=xylim, norm=LogNorm(vmin=0.15))\n",
    "plt.xlim([0,xylim])\n",
    "plt.ylim([0,xylim])\n",
    "plt.xlabel(\"Likes to hoax posts\")\n",
    "plt.ylabel(\"Likes to non-hoax posts\")\n",
    "plt.set_cmap(\"YlOrRd\")\n",
    "#legend\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('N. of users')\n",
    "plt.savefig(\"userlikes_hist2d.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of hoax likes proportion for intersection users \n",
    "userlikes_split = likes_per_user_split_count(datadict, f=lambda x: x in both_likers)\n",
    "# userlikes_split = likes_per_user_split_count(datadict)\n",
    "lim = 10  # minimum total number of likes\n",
    "mask = (userlikes_split[:,0] + userlikes_split[:,1] >= lim)\n",
    "x = userlikes_split[mask, 0]\n",
    "y = userlikes_split[mask, 1]\n",
    "w = x + y\n",
    "p = x / w\n",
    "nbins = int(np.log2(len(x)))+2\n",
    "plt.hist(p, bins=np.linspace(0,1,lim))\n",
    "plt.xlim([0,1])\n",
    "plt.xlabel(\"Likes to hoax posts / total likes\")\n",
    "plt.ylabel(\"N. of users\")\n",
    "plt.savefig(\"bothusers_hist.pdf\")\n",
    "plt.show()\n",
    "plt.hist(p, weights=w, bins=lim)\n",
    "#plt.yscale('log')\n",
    "plt.xlabel(\"Likes to hoax posts / total likes\")\n",
    "plt.ylabel(\"Weighted n. of users\")\n",
    "plt.savefig(\"allmixedusers.png\")\n",
    "plt.show()\n",
    "print(\"N. of users with p: 0.25<p<=0.75 => %d\" % len(p[(p>0.25)*(p<=0.75)]))"
   ]
  },
  {
   "cell_type": "heading",
   "level": 2,
   "metadata": {},
   "source": [
    "Common users page vs page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create new dict {pageid: list of likers}\n",
    "pageslikesdict = dict()\n",
    "for postid, likes in datadict.items():\n",
    "    pageid = postid.split('_')[0]\n",
    "    if pageid in pageslikesdict:\n",
    "        pageslikesdict[pageid] += likes\n",
    "    else:\n",
    "        pageslikesdict[pageid] = likes\n",
    "for pageid, likes in pageslikesdict.items():\n",
    "    pageslikesdict[pageid] = set(pageslikesdict[pageid])\n",
    "    # print(\"%s %d %d\" % (pageid, (pageid in pages_hoax), len(likes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Likers in common for pages as a dict {(pageid, pageid): # of users in common}\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "print(len(list(combinations(pages_hoax+pages_nonhoax, 2))))\n",
    "commondict = dict()\n",
    "# for pair in combinations(pages_hoax+pages_nonhoax, 2):\n",
    "for pair in combinations_with_replacement(pages_hoax+pages_nonhoax, 2):\n",
    "    commondict[pair] = len( pageslikesdict[pair[0]] & pageslikesdict[pair[1]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the likers in common as a matrix and as an image\n",
    "from matplotlib.colors import LogNorm\n",
    "M = np.zeros((32,32), dtype=np.int)\n",
    "pageN = {p: i for i, p in enumerate(pages_hoax+pages_nonhoax)}\n",
    "for pair, nusers in commondict.items():\n",
    "    M[pageN[pair[0]], pageN[pair[1]]] = nusers\n",
    "print(M)\n",
    "np.savetxt(\"pagesusers_matrix.csv\", M,  delimiter=',')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(M + np.transpose(M), interpolation='nearest', norm=LogNorm())\n",
    "\n",
    "plt.axvline(13.6, color='k')\n",
    "plt.axhline(13.6, color='k')\n",
    "plt.text(6.8, -2, \"Hoax\\npages\", \n",
    "         fontsize=12,\n",
    "         horizontalalignment='center')\n",
    "plt.text(22, -2, \"Non-hoax\\npages\", \n",
    "         fontsize=12,\n",
    "         horizontalalignment='center')\n",
    "plt.text(-4, 6.8, \"Hoax\\npages\", \n",
    "         fontsize=12,\n",
    "         horizontalalignment='right',\n",
    "         verticalalignment='center')\n",
    "plt.text(-4, 22, \"Non-hoax\\npages\", \n",
    "         fontsize=12,\n",
    "         horizontalalignment='right',\n",
    "         verticalalignment='center')\n",
    "\n",
    "plt.set_cmap(\"GnBu\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('N. of users in common')\n",
    "fig.subplots_adjust(top=0.85, left=0.27)\n",
    "fig.savefig(\"users_pages.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(M + np.transpose(M))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
